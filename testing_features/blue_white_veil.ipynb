{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, mask_path):\n",
    "    \"\"\"load the image and its mask\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return image, mask\n",
    "\n",
    "def detect_blue_white(image, mask):\n",
    "    \"\"\"detect blue-white veil areas in the image using the mask\"\"\"\n",
    "\n",
    "    # crop the image using the mask so that we only work with the lesion\n",
    "    cropped_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # convert the cropped image to HSV \n",
    "    hsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # define bounds for color detection - HUE | SATURATION | VALUE (brightness)\n",
    "    lower_blue = np.array([90, 20, 80])\n",
    "    upper_blue = np.array([150, 150, 150])\n",
    "    \n",
    "    # creates a new mask where all pixels fall within the defined bounds\n",
    "    detected_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    return detected_mask\n",
    "\n",
    "def coverage_ratio(detected_mask, mask):\n",
    "    veil_area = np.sum(detected_mask > 0) # total area of the blue-white veil\n",
    "    total_area = np.sum(mask > 0)\n",
    "    \n",
    "    coverage_ratio = round(veil_area / total_area, 4)\n",
    "    \n",
    "    return coverage_ratio\n",
    "\n",
    "\n",
    "def blue_white_veil(image_path, mask_path):\n",
    "    \"\"\"calculate the coverage ratio of blue-white veil areas\"\"\"\n",
    "    image, mask = load_image(image_path, mask_path)\n",
    "    detected_mask = detect_blue_white(image, mask)\n",
    "    result = coverage_ratio(detected_mask, mask)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images(image_path, mask_path, save_folder):\n",
    "    '''used to test images to visually assess  the correctness of our algorithm'''\n",
    "    image, mask = load_image(image_path, mask_path)\n",
    "    detected_mask = detect_blue_white(image, mask)\n",
    "    result = coverage_ratio(detected_mask, mask)\n",
    "    \n",
    "    # check if the save folder exists, if not, create it\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    \n",
    "    \"\"\"display the original, mask, and detected mask images with coverage ratio and saves them in given folder\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('Manual Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(detected_mask, cv2.COLOR_GRAY2RGB))\n",
    "    plt.title(f'Detected Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f'Coverage Ratio: {result:.2%}')\n",
    "    \n",
    "    # save the figure to the designated save folder\n",
    "    save_path = os.path.join(save_folder, f\"result_{os.path.basename(image_path)}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looping over images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_340_714_314.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/1.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/2.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/3.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/4.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/5.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/images/6.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/MEL/bad/images/lucie/PAT_262_402_14.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/NEV/good/images/PAT_672_1272_705.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/SCC/bad/images/david/PAT_131_197_974.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    '../good_bad_images/SEK/good/images/PAT_893_1697_613.png',\n",
    "    '../good_bad_images/MEL/good/images/lucie/PAT_995_1867_165.png',\n",
    "    \n",
    "]\n",
    "\n",
    "mask_paths = [\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_340_714_314_mask.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/1.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/2.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/3.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/4.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/5.png',\n",
    "    '../testing_features/testing_images/blue_white_veil/masks/6.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/MEL/bad/masks/lucie/PAT_262_402_14_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/NEV/good/masks/PAT_672_1272_705_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/SCC/bad/masks/david/PAT_131_197_974_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "    '../good_bad_images/SEK/good/masks/PAT_893_1697_613_mask.png',\n",
    "    '../good_bad_images/MEL/good/masks/lucie/PAT_995_1867_165_mask.png',\n",
    "]\n",
    "\n",
    "# Loop over the paths and test each image\n",
    "for img_path, msk_path in zip(image_paths, mask_paths):\n",
    "    test_images(img_path, msk_path, '../testing_features/testing_images/blue_white_veil/results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
